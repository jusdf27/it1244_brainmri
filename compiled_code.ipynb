{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style = \"font-family: Cambria\">**Task: Classification model to accurately distinguish benign and malignant tumours**</span>\n",
    "\n",
    "Here are some of the references that we used when approaching this task:\n",
    "1. Nguyen, A., Yosinski, J., & Clune, J. (2015). Deep neural networks are easily fooled: High confidence predictions for unrecognizable images. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 427-436).\n",
    "\n",
    "2. Anaya-Isaza, A., Mera-Jiménez, L., Verdugo-Alejo, L., & Sarasti, L. (2023). Optimizing MRI-based brain tumour classification and detection using AI: A comparative analysis of neural networks, transfer learning, data augmentation, and the cross-transformer network. European journal of radiology open, 10, 100484. https://doi.org/10.1016/j.ejro.2023.100484\n",
    "\n",
    "3. Arsa, Dewa Made Sri, and Anak Agung Ngurah Hary Susila. “VGG16 in Batik Classification Based on Random Forest.” In 2019 International Conference on Information Management and Technology (ICIMTech), 295–99. Jakarta/Bali, Indonesia: IEEE, 2019. https://doi.org/10.1109/ICIMTech.2019.8843844. \n",
    "\n",
    "4. Selvaraju, Ramprasaath R., Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh, and Dhruv Batra. “Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization.” In 2017 IEEE International Conference on Computer Vision (ICCV), 618–26. Venice: IEEE, 2017. https://doi.org/10.1109/ICCV.2017.74.\n",
    "\n",
    "\n",
    "\n",
    "Some limitations we wish to resolve:\n",
    "1. Nguyen et al. (2015) touched on the unpredictable behaviour of AlexNet. Hence, due to the blackbox nature of CNN, we could not explain the rationale behind the unpredictable nature. Hence, we wish to improve on the interpretability of CNN in image classifications through the use of GradCAM.\n",
    "2. Anaya-Isaza et al. explored geometric flipping image augmentation in their work. We wish to extend and further explore other image augmentation techniques with Keras ImageDataGenerator to improve robustness of training with limited datasets.\n",
    "3. Arsa et al. explored the use of VGG16-Random Forest for Batik Classification, we wish to extend on it by exploring the VGG16-XGBoost pairing and VGG16-ANN in our image classification due to the strong regularisation potential of XGBoost and regularisation tuning by dropout layer.\n",
    "\n",
    "\n",
    "\n",
    "Done by\n",
    "- Justin Tan Min Shi (A0217325L)\n",
    "- Han Yong Yi Jace (A0221948Y)\n",
    "- Sng Zhi Wen Collin (A0252248E)\n",
    "- Ryan Justyn (A0276053E)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"font-family: Cambria\">Content explorer</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order, this notebook is categorised into:\n",
    "1. [Helper functions](#helper-functions)\n",
    "- General functions i.e., plotting , image augmentation\n",
    "- Preprocessing functions\n",
    "- GradCAM Helper functions\n",
    "2. [Data Preparation](#prepare)\n",
    "3. [Baseline model](#baseline)\n",
    "4. [VGG16-ANN model](#ann)\n",
    "5. [VGG16-XgBoost model](#xgboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"font-family: Cambria\"> Dataset filepaths </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please change the file paths for the benign and malignant datasets here\n",
    "# Each filepath should points to a folder containing the image data for benign and malignant classes respectively\n",
    "\n",
    "benign_filepath = \"./Dataset/Image Dataset/Brain Tumor/data/benign\"\n",
    "malignant_filepath = \"./Dataset/Image Dataset/Brain Tumor/data/malignant\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"font-family: Cambria\">Installing dependencies and imports</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment and run to install relevant packages\n",
    "#Note that this notebook may not run for newer keras versions (ImageDataGenerator is depreceated)\n",
    "\"\"\"\n",
    "!pip install numpy==1.24.3\n",
    "!pip install pandas==1.5.3\n",
    "!pip install matplotlib==3.6.3\n",
    "!pip install imutils==0.5.4\n",
    "!pip install opencv-python==4.9.0.80\n",
    "!pip install ImageHash==4.3.1\n",
    "!pip install tqdm==4.65.0\n",
    "!pip install scikit-learn==1.4.1.post1\n",
    "!pip install scikit-image==0.22.0\n",
    "!pip install xgboost==2.0.3\n",
    "!pip install scikeras==0.12.0\n",
    "!pip install keras==2.15.0\n",
    "!pip install tensorflow\n",
    "!pip install GraphViz\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import imutils\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import imagehash\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from skimage import color\n",
    "import xgboost as XGBoost\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.applications import VGG16 \n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Activation, Flatten, Dropout, Conv2D, MaxPool2D, BatchNormalization, MaxPooling2D\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
    "\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score, f1_score, accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id = \"helper-functions\"></a> <span style = \"font-family: Cambria\">**Helper functions**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style = \"font-family: Cambria\">General functions</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"font-family: Cambria\">1. Finding images from filesystem</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fileList(source):\n",
    "    '''\n",
    "    Returns list of filepaths with .jpg extensions from root\n",
    "    '''\n",
    "    matches = []\n",
    "    for root, _, filenames in os.walk(source):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith((\".jpg\")):\n",
    "                matches.append(os.path.join(root, filename))\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"font-family: Cambria\">2. Plot helper functions</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_plot(images, dim = (10,10)):\n",
    "    '''\n",
    "    Display the images in a grid.\n",
    "\n",
    "    Args:\n",
    "        image (nd.array): Input image (numpy array).\n",
    "    '''\n",
    "    rows, cols = dim\n",
    "    r_c, c_c = 0, 0\n",
    "    fig = plt.figure(figsize=(1.7*rows, 1.3*cols))\n",
    "\n",
    "    #Looping over for i = rows x cols \n",
    "    for i, image in enumerate(images[:(rows*cols)]):\n",
    "        fig.add_subplot(rows, cols, i+1)\n",
    "        plt.imshow(image)\n",
    "        plt.tight_layout()\n",
    "        plt.axis(False)\n",
    "\n",
    "        r_c+=1\n",
    "        c_c+=1\n",
    "\n",
    "    plt.subplots_adjust(hspace=0, wspace=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"font-family: Cambria\">3. Shuffling 2 arrays</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffling(X, y):\n",
    "    \"\"\"\n",
    "    Shuffle 2 numpy arrays in the same order\n",
    "\n",
    "    Args:\n",
    "        X (nd.array)\n",
    "        y (nd.array)\n",
    "    \"\"\"\n",
    "    p = np.random.permutation(len(X))\n",
    "    return X[p], y[p]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"font-family: Cambria\">4. Image augmentation</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    samplewise_center = True,\n",
    "    samplewise_std_normalization = True,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    fill_mode=\"nearest\")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(\n",
    "    samplewise_center = True,\n",
    "    samplewise_std_normalization = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"font-family: Cambria\">5. Initialising VGG16 TF model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vgg16tf():\n",
    "    \"\"\"\n",
    "    Creates a VGG16 transfer learning model with a customer classifier\n",
    "\n",
    "    Returns:\n",
    "        model (keras.Model)\n",
    "    \"\"\"\n",
    "\n",
    "    inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "    x = VGG16(input_tensor=inputs ,weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "    x.trainable = False\n",
    "\n",
    "    x = Flatten()(x.output)\n",
    "    x = Dense(256, activation=\"relu\")(x)\n",
    "    x = Dropout(rate=0.4)(x)\n",
    "    x = Dense(2, activation=\"softmax\")(x)\n",
    "    model = tf.keras.Model(inputs, x)\n",
    "\n",
    "    return model\n",
    "\n",
    "create_vgg16tf().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"font-family: Cambria\">6. Loading model with best weights</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_best_model(path, create_model_fn):\n",
    "    \"\"\"\n",
    "    Load model with best weights.\n",
    "\n",
    "    Args:\n",
    "        path (str): Filepath of .h5 file containing the best weights.\n",
    "        create_model_fn (function): Function to create empty model, should be same model architecture as weights file\n",
    "    \"\"\"\n",
    "\n",
    "    model = create_model_fn()\n",
    "    model.load_weights(path)\n",
    "\n",
    "    return model    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"font-family: Cambria\">7. Additional metrics for VGG16-ANN model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def added_metrics(pred_prob, grd_truth):\n",
    "    \"\"\"\n",
    "    Custom metrics function for VGG16-ANN\n",
    "\n",
    "    Args:\n",
    "        pred_prob (nd.array): Predictions of model (n x 2)\n",
    "        grd_truth (nd.array): Labels (n x 2)\n",
    "    \n",
    "    Returns:\n",
    "        (list) List of metrics\n",
    "    \"\"\"\n",
    "    pred = np.argmax(pred_prob, axis = 1)\n",
    "    grd_truth = np.argmax(grd_truth, axis = 1)\n",
    "    tn, fp, fn, tp = confusion_matrix(pred, grd_truth).ravel()\n",
    "\n",
    "    accuracy = (tp+tn)/(fp+fn+tp+tn)\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "\n",
    "    return [tn, tp, fn, fp, precision, accuracy, recall]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id = \"preprocess\"></a><span style = \"font-family: Cambria\">Dataset processing functions</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"font-family: Cambria\">1. Removing near duplicates</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images_in_row(image_paths, labels=None, size=(5, 5)):\n",
    "    \"\"\"\n",
    "      Plot images in a row\n",
    "\n",
    "      Args:\n",
    "          image_paths (list): List of image paths\n",
    "          labels (list): Title for plots\n",
    "          size (tuple): Size of figure \n",
    "    \"\"\"\n",
    "    num_images = len(image_paths)\n",
    "    if num_images == 0:\n",
    "        return\n",
    "\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(num_images * size[0]/3, size[1]))\n",
    "\n",
    "    for i, (image_path, label) in enumerate(zip(image_paths, labels)):\n",
    "        image = Image.open(image_path)\n",
    "        axes[i].imshow(image)\n",
    "        axes[i].axis('off')\n",
    "        if labels:\n",
    "            axes[i].set_title(label)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def find_near_duplicates(image_paths, threshold=5, verbose=0):\n",
    "      \"\"\"\n",
    "      Utilises phash from imagehash library to remove duplicates and near duplicates from dataset.\n",
    "      Shows number of duplicated and unique images from each filepaths\n",
    "\n",
    "      Args:\n",
    "          image_paths (list): List of image paths\n",
    "          threshold (int or float): Threshold used to determine near duplicates (minimum hamming difference \n",
    "                                    of image hashs to be considered unique)\n",
    "          verbose (int): 0 - No plots\n",
    "                         1 - Show rows of duplicated images\n",
    "      \n",
    "      Returns:\n",
    "          unique_image_paths (list): List of unique image paths\n",
    "      \"\"\"\n",
    "\n",
    "      # Dictionary to store hashes for each image\n",
    "      image_hashes = {}\n",
    "      # List to store near-duplicate pairs\n",
    "      near_dups = {}\n",
    "      # Iterate over all image paths\n",
    "      for image_path in image_paths:\n",
    "          # Load image\n",
    "          image = Image.open(image_path).convert('L')  # Convert to grayscale\n",
    "          # Calculate perceptual hash\n",
    "          image_hash = imagehash.phash(image)\n",
    "          # Store hash in dictionary\n",
    "          image_hashes[image_path] = image_hash\n",
    "      # Compare hashes to find near-duplicates\n",
    "      for path1, hash1 in image_hashes.items():\n",
    "        #if dup already considered avoid overlap\n",
    "        if path1 in near_dups:\n",
    "          continue\n",
    "        list_of_dups = []\n",
    "        dup_image_names=[]\n",
    "        for path2, hash2 in image_hashes.items():\n",
    "\n",
    "          # If images are not the same and if the hamming distance of 2 images is less than threshold\n",
    "          # This parts tracks the duplicated images\n",
    "          if path1 != path2 and hash1 - hash2 < threshold:\n",
    "            near_dups[path2]=hash2\n",
    "            if len(list_of_dups) ==0:\n",
    "              list_of_dups.append(path1)\n",
    "              dup_image_names.append(os.path.basename(path1))\n",
    "            list_of_dups.append(path2)\n",
    "            dup_image_names.append(os.path.basename(path2))\n",
    "        \n",
    "        if verbose == 1:\n",
    "          if len(list_of_dups) >0:\n",
    "            print(os.path.dirname(list_of_dups[0]))\n",
    "            print(dup_image_names)\n",
    "    \n",
    "      unique_image_paths = []\n",
    "      tumour_count = 0\n",
    "      \n",
    "      for path in image_paths:\n",
    "        if path not in near_dups:\n",
    "          unique_image_paths.append(path)\n",
    "          tumour_count += 1\n",
    "    \n",
    "      print(f\"Number of duplicated {os.path.basename(os.path.dirname(path))} tumours: {len(near_dups)}\")\n",
    "      print(f\"Number of {os.path.basename(os.path.dirname(path))} tumours: {tumour_count}\")\n",
    "      return unique_image_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"font-family: Cambria\">2. Crop image</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_img(img):\n",
    "    \"\"\"\n",
    "    Crops out majority of the background and centralised the brain\n",
    "\n",
    "    Args:\n",
    "        img (nd.array)\n",
    "    \n",
    "    Returns:\n",
    "        new_imgs(nd.array): Cropped image resized to 224 pixels by 224 pixels\n",
    "    \"\"\"\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # Clearing noises\n",
    "    thresh = cv2.threshold(gray, 20, 255, cv2.THRESH_BINARY)[1]\n",
    "    thresh = cv2.erode(thresh, None, iterations=2)\n",
    "    thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "\n",
    "    # Finding contours and grab the main image\n",
    "    contours = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = imutils.grab_contours(contours)\n",
    "    c = max(contours, key = cv2.contourArea)\n",
    "\n",
    "    # Finding boundaries\n",
    "    left = tuple(c[c[:, :, 0].argmin()][0])\n",
    "    right = tuple(c[c[:, :, 0].argmax()][0])\n",
    "    top = tuple(c[c[:, :, 1].argmin()][0])\n",
    "    bottom = tuple(c[c[:, :, 1].argmax()][0])\n",
    "\n",
    "    # New image cropping\n",
    "    new_img = img[top[1] : bottom[1], left[0] : right[0]]\n",
    "    new_img = cv2.resize(new_img, (224,224))\n",
    "\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"font-family: Cambria\">3. Image mask</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask(image):\n",
    "    '''\n",
    "\n",
    "    Create a binary mask separating the brain from the background, postprocess and apply the brain mask to original.\n",
    "\n",
    "    Args:\n",
    "        image (nd.array): Input image (numpy array).\n",
    "\n",
    "    Returns:\n",
    "        masked_image (nd.array): Image with the mask applied.\n",
    "    '''\n",
    "\n",
    "    # Apply thresholding to create a binary mask separating the brain from the background\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray_image, (7,7), 0)\n",
    "    normalized = cv2.normalize(blur, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    _, thresh = cv2.threshold(normalized, 10, 255, cv2.THRESH_BINARY)\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "\n",
    "    # Postprocessing\n",
    "    contours, _ = cv2.findContours(opening, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    brain_mask = np.zeros_like(normalized)\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area > 500:  # threshold\n",
    "            cv2.drawContours(brain_mask, [cnt], -1, 255, -1)\n",
    "\n",
    "    # Apply the brain mask to the original image\n",
    "    masked_brain = cv2.bitwise_and(image, image, mask=brain_mask)\n",
    "\n",
    "    return masked_brain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"font-family: Cambria\">4. Image Augmentation for class imbalance</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_minority_class(train_X, train_y, verbose=0, seed=42):\n",
    "    '''\n",
    "    Augment only benign images in train X and from there, apppend to train X and y.\n",
    "    \n",
    "    Args:\n",
    "        train_X (nd.array): Input image (numpy array).\n",
    "        train_y (nd.array): Class labels (numpy array).\n",
    "\n",
    "    Returns:\n",
    "        train_X (nd.array): Input image with more benign images.\n",
    "        train_y (nd.array): Class labels with more 0s.\n",
    "    '''\n",
    "\n",
    "    random.seed(seed)\n",
    "    _, counts = np.unique(train_y, return_counts = True)\n",
    "    min_class = np.argmin(counts)\n",
    "\n",
    "    augment_count = max((max(counts)//min(counts)) - 1, 1) * min(counts)\n",
    "\n",
    "    # Separate benign images in train_X\n",
    "    min_class_idx = np.argwhere(train_y==min_class).reshape(1,-1)[0]\n",
    "    train_X_minclass = train_X[min_class_idx]\n",
    "\n",
    "    # Generator seed provides seeds for image augmentation based on parent seed\n",
    "    generator_seed = [random.randint(0,10000) for _ in range(augment_count)]\n",
    "    imba_augmenter = ImageDataGenerator()\n",
    "\n",
    "    new_imgs=[]\n",
    "    for count, img in enumerate(train_X_minclass):\n",
    "        if count >= augment_count:\n",
    "            break\n",
    "        \n",
    "        random.seed(generator_seed[count])\n",
    "\n",
    "        ### EDIT AUGMENT PARAMETERS HERE\n",
    "        augment_param = {\n",
    "            \"theta\": random.randint(-35, 35),\n",
    "            \"shear\": random.uniform(0, 0.1),\n",
    "            \"tx\": random.uniform(0.8, 1.3),\n",
    "            \"ty\": random.uniform(0.8, 1.3),\n",
    "            \"zx\": random.uniform(0.8, 1.3),\n",
    "            \"zy\": random.uniform(0.8, 1.3),\n",
    "            \"flip_horizontal\": True,\n",
    "            \"flip_vertical\": bool(random.randint(0, 1)),\n",
    "        }\n",
    "        \n",
    "        new_img = imba_augmenter.apply_transform(img, augment_param)\n",
    "        new_imgs.append(new_img)\n",
    "        \n",
    "        # Verbose of 1 allows to see how is the augmentation like\n",
    "        if verbose == 1:\n",
    "            print(augment_param)\n",
    "            plt.imshow(new_img)\n",
    "            plt.show()\n",
    "\n",
    "        train_X = np.append(train_X, new_img[np.newaxis,:,:,:], axis=0)\n",
    "        train_y = np.append(train_y, min_class)\n",
    "        train_X, train_y = shuffling(train_X, train_y)\n",
    "    \n",
    "    # Verbose of 2 provides grid plot of augmented images\n",
    "    if verbose == 2:\n",
    "        grid_plot(new_imgs)\n",
    "\n",
    "    return train_X, train_y\n",
    "\n",
    "#USAGE: augmented_images = augment_minority_class(train_X, train_y, verbose=1)\n",
    "\n",
    "\n",
    "def augment_images_xgboost(input, num_of_images, verbose=0, seed=42):\n",
    "    '''\n",
    "    Slightly different augment function. Able to augment benign and malignant class separately\n",
    "    with stated number of images\n",
    "    \n",
    "    Args:\n",
    "        input (nd.array): Input image (numpy array).\n",
    "        num_of_images (int): Number of times to augment\n",
    "\n",
    "    Returns:\n",
    "        new_imgs (nd.array): Input image with more benign images.\n",
    "    '''\n",
    "\n",
    "    random.seed(seed)\n",
    "    if not isinstance(input[0], np.ndarray) or not len(input[0].shape) >= 2:\n",
    "        input = [cv2.imread(path) for path in input]\n",
    "\n",
    "    # Generator seed provides seeds for image augmentation based on parent seed\n",
    "    generator_seed = [random.randint(0,10000) for _ in range(num_of_images)]\n",
    "    imba_augmenter = ImageDataGenerator()\n",
    "\n",
    "    new_imgs = []\n",
    "    for count in range(num_of_images):\n",
    "        if count < len(input):\n",
    "            index = count\n",
    "        else:\n",
    "            index = random.randint(0, len(input)-1)\n",
    "\n",
    "        img = input[index]\n",
    "\n",
    "        random.seed(generator_seed[count])\n",
    "\n",
    "        ### EDIT AUGMENT PARAMETERS HERE\n",
    "        augment_param = {\n",
    "            \"theta\": random.randint(-35,35),\n",
    "            \"shear\": random.uniform(0, 0.1),\n",
    "            \"zx\": random.uniform(0.8, 1.3),\n",
    "            \"zy\": random.uniform(0.8, 1.3),\n",
    "            \"flip_horizontal\": True,\n",
    "            \"flip_vertical\": bool(random.randint(0, 1))\n",
    "        }\n",
    "\n",
    "        new_img = imba_augmenter.apply_transform(img, augment_param)\n",
    "        \n",
    "        # Verbose of 1 allows to see how is the augmentation like\n",
    "        if verbose == 1:\n",
    "            print(augment_param)\n",
    "            plt.imshow(new_img)\n",
    "            plt.show()\n",
    "        new_imgs.append(new_img)\n",
    "    return np.array(new_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"font-family: Cambria\">5. Master preprocessing pipeline</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(img_paths, verbose=0):\n",
    "    '''\n",
    "    Read the images from image paths and preprocess images using all the above preprocessing functions (1-4).\n",
    "    \n",
    "    Args:\n",
    "        img_paths (List): List of file paths\n",
    "\n",
    "    Returns:\n",
    "        processed (List): List of numpy arrays of unique images cropped and masked.\n",
    "    '''\n",
    "    img_paths_no_dup = find_near_duplicates(img_paths, verbose=verbose)\n",
    "    img_list = [cv2.imread(path) for path in img_paths_no_dup]\n",
    "\n",
    "    processed = []\n",
    "    for img in img_list:\n",
    "        img = mask(img)\n",
    "        processed.append(crop_img(img))\n",
    "\n",
    "    return processed\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id = \"explain\"></a><span style = \"font-family: Cambria\">GradCAM helper function</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create gradcam model with input image connected with output of last pooling layer and output\n",
    "\n",
    "def grad_heatmap(model, img_bg_data, img_bg_label , layer_name_for_grad_cal, dim=(7,10)):\n",
    "    \"\"\"\n",
    "    Provides plots of GradCAM heatmap visualisations using grid_plot\n",
    "    Code for computing GradCAM heatmap and visualising it is obtained from:\n",
    "        fchollet (2021). Grad-CAM class activation visualization. \n",
    "        Retrieved from: https://keras.io/examples/vision/grad_cam/\n",
    "\n",
    "    \n",
    "    GradCAM algorithm referenced from \n",
    "        Selvaraju, Ramprasaath R., Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh, \n",
    "        and Dhruv Batra. “Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization.” \n",
    "        In 2017 IEEE International Conference on Computer Vision (ICCV), 618–26. \n",
    "        Venice: IEEE, 2017. https://doi.org/10.1109/ICCV.2017.74.\n",
    "\n",
    "        \n",
    "    Args: \n",
    "        model (keras.Model)\n",
    "        img_bg_data (List): List of image arrays (rank 3 numpy arrays)\n",
    "        img_bg_label (nd.array): numpy array (rank 2) e.g. [[0 1][1 0][1 0]]\n",
    "        layer_name_for_grad_cal (str): Ideally layer.name of last convolution/ pooling layer\n",
    "        dim (tuple): Gradcam will run through top (r x c) and output in a grid plot\n",
    "    \n",
    "    Return: None\n",
    "\n",
    "    Shows a matplotlib figure with GradCAM heatmap for images \n",
    "    dim = (row, col) control number of images (row x col) to be plotted\n",
    "    \"\"\"\n",
    "\n",
    "    grad_model = keras.Model(\n",
    "        model.inputs, [model.get_layer(layer_name_for_grad_cal).output, model.output]\n",
    "    )\n",
    "\n",
    "    #Initializing matplotlib parameters\n",
    "    alpha = 0.4\n",
    "    rows, cols = dim\n",
    "    r_c, c_c = 0, 0\n",
    "    fig = plt.figure(figsize=(24, 16))\n",
    "\n",
    "    #Looping over for i = rows x cols \n",
    "    for i, img in tqdm(enumerate(img_bg_data[:(rows*cols)])):\n",
    "        fig.add_subplot(rows, cols, i+1)\n",
    "\n",
    "        #Initialising train images for gradcam from img_bg_data\n",
    "        img_array = np.expand_dims(img, axis=0)\n",
    "\n",
    "        #Here onwards ref: https://keras.io/examples/vision/grad_cam/\n",
    "        #Track gradient change in grad_model with img_array \n",
    "        with tf.GradientTape() as tape:\n",
    "            last_conv_layer_output, preds = grad_model(img_array)\n",
    "            pred_index = tf.argmax(preds, axis = -1)\n",
    "            class_channel = preds[:,int(pred_index.numpy())]\n",
    "\n",
    "        # Initialising labels (segregating for 1 or 2 output models)\n",
    "        if len(img_bg_label.shape) != 1:\n",
    "            model_pred = pred_index.numpy()\n",
    "            grd_truth = np.argmax(img_bg_label,axis=1)[i]\n",
    "        else:\n",
    "            model_pred = int(tf.cast(preds>0.5, tf.int32).numpy())\n",
    "            grd_truth = img_bg_label[i]\n",
    "\n",
    "        # Gradient of output with respect to last convolution layer\n",
    "        grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "\n",
    "        # This is a vector where each entry is the mean intensity of the gradient\n",
    "        # over a specific feature map channel\n",
    "        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "        # We multiply each channel in the feature map array\n",
    "        # by \"how important this channel is\" with regard to the top predicted class\n",
    "        # then sum all the channels to obtain the heatmap class activation\n",
    "        last_conv_layer_output = last_conv_layer_output[0]\n",
    "        heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "\n",
    "        heatmap = tf.squeeze(heatmap)\n",
    "        heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "        heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "        # Use jet colormap to colorize heatmap\n",
    "        jet = mpl.colormaps[\"jet\"]\n",
    "        jet_colors = jet(np.arange(256))[:, :3]\n",
    "        jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "        # Create an image with RGB colorized heatmap\n",
    "        jet_heatmap = keras.utils.array_to_img(jet_heatmap)\n",
    "        jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "        jet_heatmap = keras.utils.img_to_array(jet_heatmap)\n",
    "\n",
    "        # Superimpose the heatmap on original image\n",
    "        superimposed_img = jet_heatmap * alpha + img\n",
    "        superimposed_img = keras.utils.array_to_img(superimposed_img)\n",
    "\n",
    "        # Display Grad CAM\n",
    "        plt.imshow(superimposed_img)\n",
    "\n",
    "        if int(model_pred) != int(grd_truth):\n",
    "            plt.title(f\"id:{i}; Pred {int(model_pred)}; Truth {int(grd_truth)}\", color=\"red\")\n",
    "        else: \n",
    "            plt.title(f\"id:{i}; Pred {int(model_pred)}; Truth {int(grd_truth)}\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.axis(False)\n",
    "\n",
    "        r_c+=1\n",
    "        c_c+=1\n",
    "\n",
    "    plt.subplots_adjust(wspace=0)\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id = \"prepare\"></a> <span style = \"font-family: Cambria\">**Data Preparation**</span>\n",
    "This part consists of:\n",
    "1. Loading and preparing unique images\n",
    "2. Splitting dataset into training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "b_dataset = Path(benign_filepath)\n",
    "m_dataset = Path(malignant_filepath)\n",
    "\n",
    "b_dataList = fileList(b_dataset)\n",
    "m_dataList = fileList(m_dataset)\n",
    "\n",
    "#Excluding outlier non-brain MRI image\n",
    "for root, _, filenames in os.walk(m_dataset):\n",
    "    for filename in filenames:\n",
    "        if filename == \"248.jpg\":\n",
    "            outlier = os.path.join(root, filename)\n",
    "\n",
    "# Imshow outlier for checks\n",
    "if outlier in m_dataList:\n",
    "    print(\"Removing outlier\")\n",
    "    plt.imshow(cv2.imread(outlier))\n",
    "    plt.show()\n",
    "    m_dataList.remove(outlier)\n",
    "\n",
    "# preprocess images\n",
    "b_imgs = preprocessing(b_dataList)\n",
    "m_imgs = preprocessing(m_dataList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise pre-processed images\n",
    "grid_plot(b_imgs)\n",
    "grid_plot(m_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"font-family: Cambria\">Split data into training and testing data</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising labels\n",
    "b_label = [0 for _ in range(len(b_imgs))]\n",
    "m_label = [1 for _ in range(len(m_imgs))]\n",
    "\n",
    "# Mixing order of class 0 and class 1\n",
    "t_imgs = b_imgs + m_imgs\n",
    "t_label = b_label + m_label\n",
    "t_List = list(zip(t_imgs, t_label))\n",
    "\n",
    "t_imgs, t_label = map(list,(zip(*t_List)))\n",
    "X, test_X, y, test_y = train_test_split(t_imgs, t_label, train_size=0.8, shuffle=True, random_state=42)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(f\"Train: {len(y)} Test: {len(test_y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id = \"baseline\"></a> <span style = \"font-family: Cambria\">**Baseline model**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional variable changes to adapt to baseline model\n",
    "y_base = y.astype(np.float32)\n",
    "test_X_base = np.array(test_X)\n",
    "test_y_base = np.array(test_y).astype(np.float32)\n",
    "img_width, img_height = 224, 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style = \"font-family: Cambria\">Baseline model creation</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metrics\n",
    "METRICS = [\"AUC\", \"binary_accuracy\", \"TruePositives\", \"TrueNegatives\", \"FalsePositives\", \"FalseNegatives\", \"Precision\", \"Recall\"]\n",
    "\n",
    "# A function to create baseline model\n",
    "def create_baseline_model(learning_rate = 0.001, optimizer = SGD, num_layers = 2, dropout_rate = 0.4):\n",
    "    '''\n",
    "    Create baseline model for hyperparameter tuning or classification.\n",
    "\n",
    "    Args:\n",
    "        learning_rate (float): The learning rate in model compile.\n",
    "        optimizer (keras.optimizer): Optimizer of choice.\n",
    "        num_layers (int): Number of convolutional layers expanded after the first 32-filter Conv layer\n",
    "        dropout_rate (float): The probability of dropping out each unit in the hidden layer to prevent overfitting.\n",
    "\n",
    "    Returns:\n",
    "        baseline_model: The model created with default / best hyperparameters.\n",
    "    '''\n",
    "\n",
    "    baseline_model = Sequential()\n",
    "    baseline_model.add(Input(shape = (img_width, img_height, 3)))\n",
    "\n",
    "    # A single 32-filter Conv layer to extract low-level features i.e., contours\n",
    "    baseline_model.add(Conv2D(filters=32, kernel_size=3, activation='relu', padding='valid'))\n",
    "    baseline_model.add(BatchNormalization()) # to normalise ReLU activation function to speed up and stabilise training\n",
    "    baseline_model.add(MaxPool2D(pool_size=(2, 2))) # Condense feature map\n",
    "\n",
    "    # Expand Conv layers to capture increasingly complex features\n",
    "    for _ in range(num_layers):\n",
    "        baseline_model.add(Conv2D(64 * (_ + 1), kernel_size=3, activation='relu', padding = \"valid\"))\n",
    "        baseline_model.add(MaxPool2D((2, 2))) # Condense feature map\n",
    "\n",
    "    # Flatten 3D output into 1D array before feeding into a fully connected layer\n",
    "    baseline_model.add(Flatten())\n",
    "    baseline_model.add(Dense(256, activation='relu')) # Extract features\n",
    "    baseline_model.add(Dropout(dropout_rate)) # prevent overfitting\n",
    "    baseline_model.add(Dense(1, activation='sigmoid')) # sigmoid fn to compute probability that the image belongs to malignant class\n",
    "    \n",
    "    # optimizer used to adjust weights and learning rates by minimising loss\n",
    "    if optimizer == 'adam':\n",
    "        opt = Adam(learning_rate=learning_rate)\n",
    "    else:\n",
    "        opt = SGD(learning_rate=learning_rate)\n",
    "\n",
    "    # compile model against binary cross entropy LF and evaluation metrics\n",
    "    baseline_model.compile(optimizer= opt, loss=keras.losses.binary_crossentropy, metrics=METRICS)\n",
    "\n",
    "    return baseline_model\n",
    "\n",
    "create_baseline_model().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style = \"font-family: Cambria\">Finetuning hyperparameters</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"font-family: Cambria\">Manually fine-tune best hyperparameters for the model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "num_folds = 5\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "best_val_loss = 1000\n",
    "filepath=\"baseline_model.weights.h5\"\n",
    "\n",
    "# from GridSearchCV\n",
    "dropout_rate = 0.4\n",
    "learning_rate = 0.01\n",
    "num_layers = 3\n",
    "optimizer = SGD\n",
    "\n",
    "skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "scores = {}\n",
    "for fold_idx, (train_idx, val_idx) in tqdm(enumerate(skf.split(X, y))):\n",
    "    \n",
    "    # Reinitialising model\n",
    "    train_X, val_X = X[train_idx], X[val_idx]\n",
    "    train_y, val_y = y[train_idx], y[val_idx] \n",
    "\n",
    "    # augment the minority (benign) class\n",
    "    train_X, train_y = augment_minority_class(train_X, train_y) \n",
    "   \n",
    "    # increase dataset and standardise trainig data\n",
    "    train_generator = train_datagen.flow(\n",
    "            x=train_X,\n",
    "            y=train_y,\n",
    "            batch_size=batch_size)  \n",
    "    \n",
    "    # standardise validation data\n",
    "    val_generator = validation_datagen.flow(\n",
    "        x=val_X,\n",
    "        y=val_y,\n",
    "        batch_size = batch_size\n",
    "    )\n",
    "    \n",
    "    # clear previous iteration and reinitialise model\n",
    "    keras.backend.clear_session()\n",
    "    baseline_model = create_baseline_model(num_layers=num_layers, dropout_rate=dropout_rate, learning_rate=learning_rate, optimizer=optimizer)\n",
    "\n",
    "    baseline_history = baseline_model.fit(train_generator,\n",
    "                        epochs=epochs,\n",
    "                        validation_data = val_generator)\n",
    "    \n",
    "    if baseline_history.history[\"val_loss\"][-1] <= best_val_loss:\n",
    "        best_val_loss = baseline_history.history[\"val_loss\"][-1] #replace\n",
    "        baseline_model.save_weights(filepath)\n",
    "\n",
    "    scores[\"loss\"], scores[\"AUC\"], scores[\"binary_accuracy\"], scores[\"TP\"], scores[\"TN\"], scores[\"FP\"], scores[\"FN\"], scores[\"precision\"], scores[\"recall\"] = baseline_model.evaluate(val_generator)\n",
    "\n",
    "    print(f\"Fold {fold_idx + 1}: {scores}\")\n",
    "\n",
    "# load best weights\n",
    "baseline_model = create_baseline_model(num_layers=num_layers, dropout_rate=dropout_rate, learning_rate=learning_rate, optimizer=optimizer)\n",
    "baseline_model.load_weights(filepath)\n",
    "\n",
    "# preprocessing test data\n",
    "test_generator = validation_datagen.flow(\n",
    "        x=test_X_base,\n",
    "        y=test_y_base\n",
    ")\n",
    "\n",
    "scores[\"loss\"], scores[\"AUC\"], scores[\"binary_accuracy\"], scores[\"TP\"], scores[\"TN\"], scores[\"FP\"], scores[\"FN\"], scores[\"precision\"], scores[\"recall\"] = baseline_model.evaluate(test_generator)\n",
    "print(f\"Performance metrics: {scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"font-family: Cambria\">Plot AUC and loss graphs</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot training & validation AUC values\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(baseline_history.history['auc'], color = \"midnightblue\")\n",
    "plt.plot(baseline_history.history['val_auc'], color = \"salmon\")\n",
    "plt.ylabel('AUC of Baseline CNN')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(baseline_history.history['loss'], color = \"midnightblue\")\n",
    "plt.plot(baseline_history.history['val_loss'], color = \"salmon\")\n",
    "plt.ylabel('Loss of Baseline CNN')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='center right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"model_metrics.jpg\", dpi = 250)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"font-family: Cambria\">Gradcam</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_heatmap(baseline_model, test_X_base, test_y_base, \"conv2d_5\", dim=(4,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id = \"ann\"></a><span style = \"font-family: Cambria\">**VGG16-ANN model**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"font-family: Cambria\">Transfer learning experiment</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will be looping through this to unfreeze layers from the back for training\n",
    "# during finetuning\n",
    "\n",
    "layers_frozen = [2, 3, 8, 9, 10, 12, 13, 14, 16, 17]\n",
    "\n",
    "\"\"\"\n",
    "Note: Runtime for this cell is very long\n",
    "\n",
    "Aim: To understand the effects of fine-tuning from different convolution layers of VGG16, \n",
    "we first trained the custom classifier for 10 epochs, before freezing the first n layers \n",
    "and training the rest of the convolutional layers at a lower learning rate.\n",
    "\n",
    "Algorithm flow:\n",
    "\n",
    "Outer loop around StratifiedKFold(n_split = 5): {\n",
    "\n",
    "    Train base VGG16-ANN model while only training custom classifier at back of model\n",
    "    Save base model weights \n",
    "\n",
    "    Inner loop around layers_frozen: {\n",
    "        Load base model weights\n",
    "        Run through layers_frozen to unfreeze selected layers\n",
    "        Finetune model for all the unfrozen layers\n",
    "        Save new model weights\n",
    "    }\n",
    "\n",
    "}\n",
    "\n",
    "Refer to the next segment \"Transfer learning exp summary\" for summary of results\n",
    "\"\"\"\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "epochs_finetune = 10\n",
    "\n",
    "finetune_means = []\n",
    "finetune_errors = []\n",
    "\n",
    "best_val_loss = 10000\n",
    "\n",
    "# To record performance across layers_frozen loops\n",
    "layer_metrics = {l:[] for l in layers_frozen}\n",
    "\n",
    "\n",
    "# Running experiment across stratifiedkfold\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "for fold_idx, (train_idx, val_idx) in tqdm(enumerate(skf.split(X, y))):\n",
    "\n",
    "    # Filepath to basemodel weights\n",
    "    fold_filepath = f\"./vggbasemodel_{fold_idx}.h5\"\n",
    "    model = create_vgg16tf()\n",
    "    \n",
    "    # Segregating train and val\n",
    "    train_X, val_X = X[train_idx], X[val_idx]\n",
    "    train_y_old, val_y_old = y[train_idx], y[val_idx] \n",
    "\n",
    "    train_X, train_y_old = augment_minority_class(train_X, train_y_old)\n",
    "    train_y = np.array([[1,0] if l == 0 else [0,1] for l in train_y_old])\n",
    "    val_y = np.array([[1,0] if l == 0 else [0,1] for l in val_y_old])\n",
    "    \n",
    "    # To flow train and val data into model\n",
    "    train_generator = train_datagen.flow(\n",
    "        x=train_X,\n",
    "        y=train_y,\n",
    "        batch_size=batch_size)\n",
    "\n",
    "    validation_generator = validation_datagen.flow(\n",
    "        x=val_X,\n",
    "        y=val_y,\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size)\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "            loss=\"categorical_crossentropy\",\n",
    "            metrics=[\"binary_accuracy\", \"AUC\"])\n",
    "    \n",
    "    epoch_history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        verbose=1)\n",
    "    \n",
    "    # Tracking metrics for base model training\n",
    "    fold_trainloss = epoch_history.history[\"loss\"]\n",
    "    fold_trainacc = epoch_history.history[\"binary_accuracy\"]\n",
    "    fold_valloss = epoch_history.history[\"val_loss\"]\n",
    "    fold_valacc = epoch_history.history[\"val_binary_accuracy\"]\n",
    "\n",
    "    # Saving model for use later\n",
    "    model.save_weights(fold_filepath)\n",
    "    \n",
    "\n",
    "    # Finetuning loop\n",
    "    for layer_num in layers_frozen:\n",
    "\n",
    "        # New file path for finetune model\n",
    "        layer_filepath = f\"./vggbasemodel_{fold_idx}_finetune_{layer_num}.h5\"\n",
    "\n",
    "        # Copy base model metrics to continue plot\n",
    "        finetune_trainloss = fold_trainloss.copy()\n",
    "        finetune_trainacc = fold_trainacc.copy()\n",
    "        finetune_valloss = fold_valloss.copy()\n",
    "        finetune_valacc = fold_valacc.copy()\n",
    "\n",
    "        # Load base model for certain fold\n",
    "        model = create_vgg16tf()\n",
    "        model.load_weights(fold_filepath)\n",
    "\n",
    "        # Freezing weights\n",
    "        for id, layer in enumerate(model.layers):\n",
    "            layer.trainable = False\n",
    "            if id > layer_num:\n",
    "                layer.trainable = True\n",
    "        \n",
    "        model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "            loss=\"categorical_crossentropy\",\n",
    "            metrics=[\"binary_accuracy\", \"AUC\"])\n",
    "        \n",
    "        epoch_history_ft = model.fit(\n",
    "            train_generator,\n",
    "            epochs=epochs_finetune,\n",
    "            validation_data=validation_generator,\n",
    "            verbose=1)\n",
    "        model.save_weights(layer_filepath)\n",
    "\n",
    "        # Continue plot with finetune metrics\n",
    "        finetune_trainloss.extend(epoch_history_ft.history[\"loss\"])\n",
    "        finetune_trainacc.extend(epoch_history_ft.history[\"binary_accuracy\"])\n",
    "        finetune_valloss.extend(epoch_history_ft.history[\"val_loss\"])\n",
    "        finetune_valacc.extend(epoch_history_ft.history[\"val_binary_accuracy\"])\n",
    "\n",
    "        #Pickle dump training history\n",
    "        finetune_history = {\n",
    "            \"loss\": finetune_trainloss,\n",
    "            \"acc\": finetune_trainacc,\n",
    "            \"val_loss\": finetune_valloss,\n",
    "            \"val_acc\": finetune_valacc\n",
    "        }\n",
    "     \n",
    "        loss, accuracy, auc = model.evaluate(validation_generator)\n",
    "        preds = model.predict(validation_generator)\n",
    "        buffer = [loss]\n",
    "        buffer.extend(added_metrics(preds, val_y))\n",
    "        \n",
    "        layer_metrics[layer_num].append(buffer)\n",
    "\n",
    "        print(f\"Fold{fold_idx} Layer{layer_num}: {added_metrics(preds, val_y)}\")\n",
    "\n",
    "        # History.history plots\n",
    "        fig, ax = plt.subplots(1,2,figsize=(13,6))\n",
    "\n",
    "        ax[0].plot(finetune_trainacc, label=\"train_acc\")\n",
    "        ax[0].plot(finetune_valacc, label=\"val_acc\")\n",
    "        ax[0].axvline(x=epochs, ymin =0, ymax=10, color=\"red\", alpha=0.5, linestyle=\"--\")\n",
    "        ax[0].set_xlabel(\"Epoch\")\n",
    "        ax[0].set_title(f\"Fold {fold_idx+1}\")\n",
    "        ax[0].legend()\n",
    "\n",
    "        ax[1].plot(finetune_trainloss, label=\"train_loss\")\n",
    "        ax[1].plot(finetune_valloss, label=\"val_loss\")\n",
    "        ax[1].axvline(x=epochs, ymin =0, ymax=10, color=\"red\", alpha=0.5, linestyle=\"--\")\n",
    "        ax[1].set_xlabel(\"Epoch\")\n",
    "        ax[1].legend()\n",
    "        plt.show()\n",
    "        \n",
    "        keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transfer learning exp summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Val predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: This layer is dependent on results from the previous cell \n",
    "# if u need the mean and error without running the previous cells you can uncomment these 2 lines:\n",
    "\n",
    "#means = [[0.6460669994354248, 0.591467696428299, 0.6758981585502625, 0.5428489506244659, 0.6624845623970032, 0.4607712388038635, 0.4052444934844971, 0.5576117932796478, 0.4481421530246735, 0.39641469717025757], [6.4, 4.8, 4.8, 5.2, 8.8, 6.4, 8.2, 7.4, 6.6, 8.4], [12.2, 16.8, 14.6, 17.2, 10.2, 18.4, 18.6, 18.4, 19.0, 17.6], [4.0, 5.6, 5.6, 5.2, 1.6, 4.0, 2.2, 3.0, 3.8, 2.0], [8.0, 3.4, 5.6, 3.0, 10.0, 1.8, 1.6, 1.8, 1.2, 2.6], [0.6038095238095238, 0.8357142857142857, 0.7219047619047618, 0.8538095238095238, 0.5023809523809524, 0.9104761904761904, 0.9204761904761904, 0.9114285714285714, 0.9404761904761905, 0.8709523809523809], [0.6086021505376344, 0.7075268817204301, 0.6337634408602151, 0.7335483870967743, 0.6206451612903225, 0.8111827956989247, 0.8754838709677418, 0.843010752688172, 0.8369892473118281, 0.8494623655913978], [0.7700314889788574, 0.7627224627224628, 0.7711167182267795, 0.7853002070393376, 0.7214141414141414, 0.824503105590062, 0.8981254189492176, 0.8631032125768968, 0.8405035865905433, 0.9051171406777815]]\n",
    "#errors = [[0.05789509557340848, 0.14546233125374053, 0.09779906780071315, 0.14980663076625234, 0.15593145096142064, 0.18000572987292435, 0.1252150276740922, 0.19599881757688642, 0.12262273448221743, 0.04791983317594967], [2.4166091947189146, 2.4819347291981715, 3.249615361854384, 2.6381811916545836, 1.1661903789690602, 1.4966629547095764, 1.3266499161421599, 1.3564659966250536, 1.8547236990991407, 1.3564659966250536], [4.707440918375928, 4.069397989875161, 4.673328578219169, 2.481934729198171, 6.4, 1.2000000000000002, 1.0198039027185568, 1.019803902718557, 0.6324555320336759, 1.4966629547095764], [2.449489742783178, 2.939387691339814, 3.6110940170535577, 3.059411708155671, 1.3564659966250536, 1.6733200530681511, 1.16619037896906, 1.0954451150103321, 2.2271057451320084, 1.2649110640673518], [4.69041575982343, 4.454211490264017, 4.586937976471886, 2.8284271247461903, 6.2289646009589745, 0.9797958971132713, 0.8, 1.16619037896906, 0.4, 1.3564659966250536], [0.2346445181260822, 0.2116986691753452, 0.23004189700230093, 0.13473413814568083, 0.3133897763607448, 0.04938625585700636, 0.04036679895718616, 0.056892307862113946, 0.02025909274874535, 0.06826983942457085], [0.08846267338933866, 0.12368115684377644, 0.05821406468250258, 0.10061298998733334, 0.17192791849239608, 0.07355530370546157, 0.026130580953262834, 0.014183769847605276, 0.06687307623148353, 0.017668469596940826], [0.05549313187578253, 0.0789901210078336, 0.12456858000894624, 0.10278538753270194, 0.36533631826904783, 0.06429224519490624, 0.04705231632623448, 0.035720820157888085, 0.0744328107363998, 0.05546636624229973]]\n",
    "\n",
    "layers_frozen = [2, 3, 8, 9, 10, 12, 13, 14, 16, 17]\n",
    "\n",
    "# Need to add 2 due to calculations (index start from 0 and id>layer_num)\n",
    "# Due to code for freezing layers \n",
    "layers_frozen = [i + 2 for i in layers_frozen]              \n",
    "\n",
    "layer_means = []\n",
    "layer_errors = []\n",
    "for layer_num, fold_metrics in layer_metrics.items():\n",
    "    fold_metrics = np.array(fold_metrics)\n",
    "    fold_means = np.mean(fold_metrics, axis = 0)\n",
    "    fold_errors = np.std(fold_metrics, axis = 0)\n",
    "    \n",
    "    layer_means.append(fold_means)\n",
    "    layer_errors.append(fold_errors)\n",
    "\n",
    "means = list(map(list,(zip(*layer_means))))\n",
    "errors = list(map(list,(zip(*layer_errors))))\n",
    "\n",
    "print(\"\\nMeans\\n\")\n",
    "print(means)\n",
    "print(\"\\nErrors\\n\")\n",
    "print(errors)\n",
    "print(\"\\n\")\n",
    "\n",
    "fig, ax = plt.subplots(1,3,figsize=(13,6))\n",
    "\n",
    "ax[0].errorbar(layers_frozen, means[0], yerr=errors[0], label=\"val_loss\")\n",
    "ax[0].set_xlabel(\"Layers frozen\")\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].errorbar(layers_frozen, means[1], yerr=errors[1], label=\"TN\")\n",
    "ax[1].errorbar(layers_frozen, means[2], yerr=errors[2], label=\"TP\")\n",
    "ax[1].errorbar(layers_frozen, means[3], yerr=errors[3], label=\"FN\")\n",
    "ax[1].errorbar(layers_frozen, means[4], yerr=errors[4], label=\"FP\")\n",
    "ax[1].set_xlabel(\"Layers frozen\")\n",
    "ax[1].legend()\n",
    "\n",
    "ax[2].errorbar(layers_frozen, means[5], yerr=errors[5], label=\"precision\")\n",
    "ax[2].errorbar(layers_frozen, means[6], yerr=errors[6], label=\"accuracy\")\n",
    "ax[2].errorbar(layers_frozen, means[7], yerr=errors[7], label=\"recall\")\n",
    "ax[2].set_xlabel(\"Layers frozen\")\n",
    "ax[2].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied the means and SD as the code block for the experiment took 2-3hrs to run\n",
    "# Just in case it went missing, and to facilitate analysis after the session\n",
    "\n",
    "layers_frozen = [2, 3, 8, 9, 10, 12, 13, 14, 16, 17]\n",
    "layers_frozen = [i + 2 for i in layers_frozen]              \n",
    "\n",
    "means = [[0.6460669994354248, 0.591467696428299, 0.6758981585502625, 0.5428489506244659, 0.6624845623970032, 0.4607712388038635, 0.4052444934844971, 0.5576117932796478, 0.4481421530246735, 0.39641469717025757], [6.4, 4.8, 4.8, 5.2, 8.8, 6.4, 8.2, 7.4, 6.6, 8.4], [12.2, 16.8, 14.6, 17.2, 10.2, 18.4, 18.6, 18.4, 19.0, 17.6], [4.0, 5.6, 5.6, 5.2, 1.6, 4.0, 2.2, 3.0, 3.8, 2.0], [8.0, 3.4, 5.6, 3.0, 10.0, 1.8, 1.6, 1.8, 1.2, 2.6], [0.6038095238095238, 0.8357142857142857, 0.7219047619047618, 0.8538095238095238, 0.5023809523809524, 0.9104761904761904, 0.9204761904761904, 0.9114285714285714, 0.9404761904761905, 0.8709523809523809], [0.6086021505376344, 0.7075268817204301, 0.6337634408602151, 0.7335483870967743, 0.6206451612903225, 0.8111827956989247, 0.8754838709677418, 0.843010752688172, 0.8369892473118281, 0.8494623655913978], [0.7700314889788574, 0.7627224627224628, 0.7711167182267795, 0.7853002070393376, 0.7214141414141414, 0.824503105590062, 0.8981254189492176, 0.8631032125768968, 0.8405035865905433, 0.9051171406777815]]\n",
    "errors = [[0.05789509557340848, 0.14546233125374053, 0.09779906780071315, 0.14980663076625234, 0.15593145096142064, 0.18000572987292435, 0.1252150276740922, 0.19599881757688642, 0.12262273448221743, 0.04791983317594967], [2.4166091947189146, 2.4819347291981715, 3.249615361854384, 2.6381811916545836, 1.1661903789690602, 1.4966629547095764, 1.3266499161421599, 1.3564659966250536, 1.8547236990991407, 1.3564659966250536], [4.707440918375928, 4.069397989875161, 4.673328578219169, 2.481934729198171, 6.4, 1.2000000000000002, 1.0198039027185568, 1.019803902718557, 0.6324555320336759, 1.4966629547095764], [2.449489742783178, 2.939387691339814, 3.6110940170535577, 3.059411708155671, 1.3564659966250536, 1.6733200530681511, 1.16619037896906, 1.0954451150103321, 2.2271057451320084, 1.2649110640673518], [4.69041575982343, 4.454211490264017, 4.586937976471886, 2.8284271247461903, 6.2289646009589745, 0.9797958971132713, 0.8, 1.16619037896906, 0.4, 1.3564659966250536], [0.2346445181260822, 0.2116986691753452, 0.23004189700230093, 0.13473413814568083, 0.3133897763607448, 0.04938625585700636, 0.04036679895718616, 0.056892307862113946, 0.02025909274874535, 0.06826983942457085], [0.08846267338933866, 0.12368115684377644, 0.05821406468250258, 0.10061298998733334, 0.17192791849239608, 0.07355530370546157, 0.026130580953262834, 0.014183769847605276, 0.06687307623148353, 0.017668469596940826], [0.05549313187578253, 0.0789901210078336, 0.12456858000894624, 0.10278538753270194, 0.36533631826904783, 0.06429224519490624, 0.04705231632623448, 0.035720820157888085, 0.0744328107363998, 0.05546636624229973]]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(13,6))\n",
    "\n",
    "ax[0].plot(layers_frozen, means[0], label=\"val_loss\", color=\"midnightblue\")\n",
    "ax[0].axvline(x = 11, ymin = 0, ymax=30, color=\"midnightblue\", alpha = 0.3, linestyle=\"--\")\n",
    "ax[0].axvline(x = 15, ymin = 0, ymax=30, color=\"midnightblue\", alpha = 0.3, linestyle=\"--\")\n",
    "ax[0].set_xlabel(\"Layers frozen\")\n",
    "ax[0].set_ylabel(\"Validation loss\")\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(layers_frozen, means[5], label=\"precision\", color=\"midnightblue\")\n",
    "ax[1].plot(layers_frozen, means[6], label=\"accuracy\", color=\"salmon\")\n",
    "ax[1].plot(layers_frozen, means[7], label=\"recall\", color=\"lightpink\")\n",
    "ax[1].axvline(x = 11, ymin = 0, ymax=30, color=\"midnightblue\", alpha = 0.3, linestyle=\"--\")\n",
    "ax[1].axvline(x = 15, ymin = 0, ymax=30, color=\"midnightblue\", alpha = 0.3, linestyle=\"--\")\n",
    "ax[1].set_xlabel(\"Layers frozen\")\n",
    "ax[1].set_ylabel(\"Metrics score\")\n",
    "ax[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied the means and SD as the code block for the experiment took 2-3hrs to run\n",
    "# Just in case it went missing, and to facilitate analysis after the session\n",
    "\n",
    "val_tfexp_means = [[0.6460669994354248, 0.591467696428299, 0.6758981585502625, 0.5428489506244659, 0.6624845623970032, 0.4607712388038635, 0.4052444934844971, 0.5576117932796478, 0.4481421530246735, 0.39641469717025757], [6.4, 4.8, 4.8, 5.2, 8.8, 6.4, 8.2, 7.4, 6.6, 8.4], [12.2, 16.8, 14.6, 17.2, 10.2, 18.4, 18.6, 18.4, 19.0, 17.6], [4.0, 5.6, 5.6, 5.2, 1.6, 4.0, 2.2, 3.0, 3.8, 2.0], [8.0, 3.4, 5.6, 3.0, 10.0, 1.8, 1.6, 1.8, 1.2, 2.6], [0.6038095238095238, 0.8357142857142857, 0.7219047619047618, 0.8538095238095238, 0.5023809523809524, 0.9104761904761904, 0.9204761904761904, 0.9114285714285714, 0.9404761904761905, 0.8709523809523809], [0.6086021505376344, 0.7075268817204301, 0.6337634408602151, 0.7335483870967743, 0.6206451612903225, 0.8111827956989247, 0.8754838709677418, 0.843010752688172, 0.8369892473118281, 0.8494623655913978], [0.7700314889788574, 0.7627224627224628, 0.7711167182267795, 0.7853002070393376, 0.7214141414141414, 0.824503105590062, 0.8981254189492176, 0.8631032125768968, 0.8405035865905433, 0.9051171406777815]]\n",
    "val_tfexp_errors = [[0.05789509557340848, 0.14546233125374053, 0.09779906780071315, 0.14980663076625234, 0.15593145096142064, 0.18000572987292435, 0.1252150276740922, 0.19599881757688642, 0.12262273448221743, 0.04791983317594967], [2.4166091947189146, 2.4819347291981715, 3.249615361854384, 2.6381811916545836, 1.1661903789690602, 1.4966629547095764, 1.3266499161421599, 1.3564659966250536, 1.8547236990991407, 1.3564659966250536], [4.707440918375928, 4.069397989875161, 4.673328578219169, 2.481934729198171, 6.4, 1.2000000000000002, 1.0198039027185568, 1.019803902718557, 0.6324555320336759, 1.4966629547095764], [2.449489742783178, 2.939387691339814, 3.6110940170535577, 3.059411708155671, 1.3564659966250536, 1.6733200530681511, 1.16619037896906, 1.0954451150103321, 2.2271057451320084, 1.2649110640673518], [4.69041575982343, 4.454211490264017, 4.586937976471886, 2.8284271247461903, 6.2289646009589745, 0.9797958971132713, 0.8, 1.16619037896906, 0.4, 1.3564659966250536], [0.2346445181260822, 0.2116986691753452, 0.23004189700230093, 0.13473413814568083, 0.3133897763607448, 0.04938625585700636, 0.04036679895718616, 0.056892307862113946, 0.02025909274874535, 0.06826983942457085], [0.08846267338933866, 0.12368115684377644, 0.05821406468250258, 0.10061298998733334, 0.17192791849239608, 0.07355530370546157, 0.026130580953262834, 0.014183769847605276, 0.06687307623148353, 0.017668469596940826], [0.05549313187578253, 0.0789901210078336, 0.12456858000894624, 0.10278538753270194, 0.36533631826904783, 0.06429224519490624, 0.04705231632623448, 0.035720820157888085, 0.0744328107363998, 0.05546636624229973]]\n",
    "\n",
    "layers_frozen = [2, 3, 8, 9, 10, 12, 13, 14, 16, 17]\n",
    "layers_frozen = [i + 2 for i in layers_frozen]              # Need to add 2 due to calculations (index start from 0 and id>layer_num)\n",
    "\n",
    "val_tf_exp = pd.DataFrame(np.array(val_tfexp_means).T.tolist(), columns = [\"Val_loss\", \"TN\", \"TP\", \"FN\", \"FP\", \"Precision\", \"Accuracy\", \"Recall\"])\n",
    "val_tf_exp[\"Layers frozen\"] = layers_frozen\n",
    "val_tf_exp = val_tf_exp.set_index(\"Layers frozen\")\n",
    "val_tf_exp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style = \"font-family: Cambria\">Final models</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style = \"font-family: Cambria\">VGG16TF - All frozen</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 15\n",
    "\n",
    "vgg16tf = create_vgg16tf()\n",
    "\n",
    "# Augmenting train data (VGG16-CNN has a 2 class output)\n",
    "X_aug, y_aug = augment_minority_class(X, y)\n",
    "y_aug_new = np.array([[1,0] if l == 0 else [0,1] for l in y_aug])\n",
    "\n",
    "train_generator = train_datagen.flow(\n",
    "    x=X_aug,\n",
    "    y=y_aug_new,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "# Test data (VGG16-CNN has a 2 class output)\n",
    "test_X_new = np.array(test_X)\n",
    "test_y_new = np.array([[1,0] if l == 0 else [0,1] for l in test_y])\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    samplewise_center = True,\n",
    "    samplewise_std_normalization = True)\n",
    "\n",
    "test_generator = test_datagen.flow(\n",
    "    x=test_X_new,\n",
    "    y=test_y_new,\n",
    "    shuffle=False,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "optimizer = Adam(learning_rate=0.00005)\n",
    "\n",
    "vgg16tf.compile(optimizer=optimizer,\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"binary_accuracy\", \"AUC\"])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True, start_from_epoch=3)\n",
    "\n",
    "epoch_history = vgg16tf.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1)\n",
    "\n",
    "\n",
    "vggtf_trainloss = epoch_history.history[\"loss\"].copy()\n",
    "vggtf_trainauc = epoch_history.history[\"auc\"].copy()\n",
    "vggtf_valloss = epoch_history.history[\"val_loss\"].copy()\n",
    "vggtf_valauc = epoch_history.history[\"val_auc\"].copy()\n",
    "\n",
    "\n",
    "# Finetuned results\n",
    "loss, accuracy, auc = vgg16tf.evaluate(test_generator)\n",
    "preds = vgg16tf.predict(test_generator)\n",
    "print(added_metrics(preds, test_y_new))\n",
    "\n",
    "\n",
    "# History.history plots\n",
    "fig, ax = plt.subplots(1,2,figsize=(13,6))\n",
    "\n",
    "ax[0].plot(vggtf_trainauc, label=\"train_auc\", color = \"midnightblue\")\n",
    "ax[0].plot(vggtf_valauc, label=\"test_auc\", color = \"salmon\")\n",
    "ax[0].set_xlabel(\"Epoch\")\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(vggtf_trainloss, label=\"train_loss\", color = \"midnightblue\")\n",
    "ax[1].plot(vggtf_valloss, label=\"test_loss\", color = \"salmon\")\n",
    "ax[1].set_xlabel(\"Epoch\")\n",
    "ax[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gradcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_heatmap(vgg16tf, X_aug, y_aug_new, \"block5_conv3\", dim=(7,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_heatmap(vgg16tf, test_X, test_y_new, \"block5_conv3\", dim=(4,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style = \"font-family: Cambria\">VGG16TF_11 - Training layer 11 onwards</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_num = 9\n",
    "batch_size = 64\n",
    "epochs = 15\n",
    "epochs_finetune = 7\n",
    "\n",
    "\n",
    "vgg16tf_11 = create_vgg16tf()\n",
    "\n",
    "# Augmenting train data (VGG16-CNN has a 2 class output)\n",
    "X_aug, y_aug = augment_minority_class(X, y)\n",
    "y_aug_new = np.array([[1,0] if l == 0 else [0,1] for l in y_aug])\n",
    "\n",
    "train_generator = train_datagen.flow(\n",
    "    x=X_aug,\n",
    "    y=y_aug_new,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "# Test data (VGG16-CNN has a 2 class output)\n",
    "test_X_new = np.array(test_X)\n",
    "test_y_new = np.array([[1,0] if l == 0 else [0,1] for l in test_y])\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    samplewise_center = True,\n",
    "    samplewise_std_normalization = True)\n",
    "\n",
    "test_generator = test_datagen.flow(\n",
    "    x=test_X_new,\n",
    "    y=test_y_new,\n",
    "    shuffle=False,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0005)\n",
    "\n",
    "# Initial learning rate\n",
    "vgg16tf_11.compile(optimizer=optimizer,\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"binary_accuracy\", \"AUC\"])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True, start_from_epoch=0)\n",
    "\n",
    "epoch_history = vgg16tf_11.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1)\n",
    "\n",
    "# Interim result\n",
    "loss, accuracy, auc = vgg16tf_11.evaluate(test_generator)\n",
    "preds = vgg16tf_11.predict(test_generator)\n",
    "print(added_metrics(preds, test_y_new))\n",
    "\n",
    "vggtf_11_trainloss = epoch_history.history[\"loss\"].copy()\n",
    "vggtf_11_trainauc = epoch_history.history[\"auc\"].copy()\n",
    "vggtf_11_valloss = epoch_history.history[\"val_loss\"].copy()\n",
    "vggtf_11_valauc = epoch_history.history[\"val_auc\"].copy()\n",
    "n = len(epoch_history.history[\"loss\"])\n",
    "\n",
    "# Unfrozen layers 11 onwards for finetuning\n",
    "for id, layer in enumerate(vgg16tf_11.layers):\n",
    "    layer.trainable = False\n",
    "    if id > layer_num:\n",
    "        layer.trainable = True\n",
    "\n",
    "optimizer.learning_rate.assign(1e-5)\n",
    "\n",
    "epoch_history_ft = vgg16tf_11.fit(\n",
    "        train_generator,\n",
    "        epochs=epochs_finetune,\n",
    "        validation_data=test_generator,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=1)\n",
    "\n",
    "vggtf_11_trainloss.extend(epoch_history_ft.history[\"loss\"].copy())\n",
    "vggtf_11_trainauc.extend(epoch_history_ft.history[\"auc\"].copy())\n",
    "vggtf_11_valloss.extend(epoch_history_ft.history[\"val_loss\"].copy())\n",
    "vggtf_11_valauc.extend(epoch_history_ft.history[\"val_auc\"].copy())\n",
    "\n",
    "# Finetuned results\n",
    "loss, accuracy, auc = vgg16tf_11.evaluate(test_generator)\n",
    "preds = vgg16tf_11.predict(test_generator)\n",
    "print(added_metrics(preds, test_y_new))\n",
    "\n",
    "# History.history plots\n",
    "fig, ax = plt.subplots(1,2,figsize=(13,6))\n",
    "\n",
    "ax[0].plot(vggtf_11_trainauc, label=\"train_auc\", color=\"midnightblue\")\n",
    "ax[0].plot(vggtf_11_valauc, label=\"test_auc\", color=\"salmon\")\n",
    "ax[0].axvline(x=n, ymin=0, ymax=10, color=\"midnightblue\", alpha=0.5, linestyle=\"--\")\n",
    "ax[0].set_xlabel(\"Epoch\")\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(vggtf_11_trainloss, label=\"train_loss\", color=\"midnightblue\")\n",
    "ax[1].plot(vggtf_11_valloss, label=\"test_loss\", color=\"salmon\")\n",
    "ax[1].axvline(x=n, ymin=0, ymax=10, color=\"midnightblue\", alpha=0.5, linestyle=\"--\")\n",
    "ax[1].set_xlabel(\"Epoch\")\n",
    "ax[1].legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gradcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_heatmap(vgg16tf_11, X_aug, y_aug_new, \"block5_conv3\", dim=(7,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_heatmap(vgg16tf_11, test_X, test_y_new, \"block5_conv3\", dim=(4,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style = \"font-family: Cambria\">VGG16TF_15 - Training layer 15 onwards</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_num = 13\n",
    "batch_size = 64\n",
    "epochs = 15\n",
    "epochs_finetune = 7\n",
    "\n",
    "\n",
    "vgg16tf_15 = create_vgg16tf()\n",
    "\n",
    "# Augmenting train data (VGG16-CNN has a 2 class output)\n",
    "X_aug, y_aug = augment_minority_class(X, y)\n",
    "y_aug_new = np.array([[1,0] if l == 0 else [0,1] for l in y_aug])\n",
    "\n",
    "train_generator = train_datagen.flow(\n",
    "    x=X_aug,\n",
    "    y=y_aug_new,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "# Test data (VGG16-CNN has a 2 class output)\n",
    "test_X_new = np.array(test_X)\n",
    "test_y_new = np.array([[1,0] if l == 0 else [0,1] for l in test_y])\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    samplewise_center = True,\n",
    "    samplewise_std_normalization = True)\n",
    "\n",
    "test_generator = test_datagen.flow(\n",
    "    x=test_X_new,\n",
    "    y=test_y_new,\n",
    "    shuffle=False,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0005)\n",
    "\n",
    "# Initial learning rate\n",
    "vgg16tf_15.compile(optimizer=optimizer,\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"binary_accuracy\", \"AUC\"])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True, start_from_epoch=0)\n",
    "\n",
    "epoch_history = vgg16tf_15.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1)\n",
    "\n",
    "# Interim result\n",
    "loss, accuracy, auc = vgg16tf_15.evaluate(test_generator)\n",
    "preds = vgg16tf_15.predict(test_generator)\n",
    "print(added_metrics(preds, test_y_new))\n",
    "\n",
    "vggtf_15_trainloss = epoch_history.history[\"loss\"].copy()\n",
    "vggtf_15_trainauc = epoch_history.history[\"auc\"].copy()\n",
    "vggtf_15_valloss = epoch_history.history[\"val_loss\"].copy()\n",
    "vggtf_15_valauc = epoch_history.history[\"val_auc\"].copy()\n",
    "n = len(epoch_history.history[\"loss\"])\n",
    "\n",
    "# Unfrozen layers 15 onwards for finetuning\n",
    "for id, layer in enumerate(vgg16tf_15.layers):\n",
    "    layer.trainable = False\n",
    "    if id > layer_num:\n",
    "        layer.trainable = True\n",
    "\n",
    "optimizer.learning_rate.assign(1e-5)\n",
    "\n",
    "epoch_history_ft = vgg16tf_15.fit(\n",
    "        train_generator,\n",
    "        epochs=epochs_finetune,\n",
    "        validation_data=test_generator,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=1)\n",
    "\n",
    "vggtf_15_trainloss.extend(epoch_history_ft.history[\"loss\"].copy())\n",
    "vggtf_15_trainauc.extend(epoch_history_ft.history[\"auc\"].copy())\n",
    "vggtf_15_valloss.extend(epoch_history_ft.history[\"val_loss\"].copy())\n",
    "vggtf_15_valauc.extend(epoch_history_ft.history[\"val_auc\"].copy())\n",
    "\n",
    "# Finetuned results\n",
    "loss, accuracy, auc = vgg16tf_15.evaluate(test_generator)\n",
    "preds = vgg16tf_15.predict(test_generator)\n",
    "print(added_metrics(preds, test_y_new))\n",
    "\n",
    "# History.history plots\n",
    "fig, ax = plt.subplots(1,2,figsize=(13,6))\n",
    "\n",
    "ax[0].plot(vggtf_15_trainauc, label=\"train_auc\", color=\"midnightblue\")\n",
    "ax[0].plot(vggtf_15_valauc, label=\"test_auc\", color=\"salmon\")\n",
    "ax[0].axvline(x=n, ymin=0, ymax=10, color=\"midnightblue\", alpha=0.5, linestyle=\"--\")\n",
    "ax[0].set_xlabel(\"Epoch\")\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(vggtf_15_trainloss, label=\"train_loss\", color=\"midnightblue\")\n",
    "ax[1].plot(vggtf_15_valloss, label=\"test_loss\", color=\"salmon\")\n",
    "ax[1].axvline(x=n, ymin=0, ymax=10, color=\"midnightblue\", alpha=0.5, linestyle=\"--\")\n",
    "ax[1].set_xlabel(\"Epoch\")\n",
    "ax[1].legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gradcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_heatmap(vgg16tf_15, X_aug, y_aug_new, \"block5_conv3\", dim=(7,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_heatmap(vgg16tf_15, test_X, test_y_new, \"block5_conv3\", dim=(4,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style = \"font-family: Cambria\">VGG16TF_18 - Training layer 18</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_num = 16\n",
    "batch_size = 64\n",
    "epochs = 15\n",
    "epochs_finetune = 7\n",
    "\n",
    "vgg16tf_18 = create_vgg16tf()\n",
    "\n",
    "# Augmenting train data (VGG16-CNN has a 2 class output)\n",
    "X_aug, y_aug = augment_minority_class(X, y)\n",
    "y_aug_new = np.array([[1,0] if l == 0 else [0,1] for l in y_aug])\n",
    "\n",
    "train_generator = train_datagen.flow(\n",
    "    x=X_aug,\n",
    "    y=y_aug_new,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "# Test data (VGG16-CNN has a 2 class output)\n",
    "test_X_new = np.array(test_X)\n",
    "test_y_new = np.array([[1,0] if l == 0 else [0,1] for l in test_y])\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    samplewise_center = True,\n",
    "    samplewise_std_normalization = True)\n",
    "\n",
    "test_generator = test_datagen.flow(\n",
    "    x=test_X_new,\n",
    "    y=test_y_new,\n",
    "    shuffle=False,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0005)\n",
    "\n",
    "# Initial learning rate\n",
    "vgg16tf_18.compile(optimizer=optimizer,\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"binary_accuracy\", \"AUC\"])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True, start_from_epoch=0)\n",
    "\n",
    "epoch_history = vgg16tf_18.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1)\n",
    "\n",
    "# Interim result\n",
    "loss, accuracy, auc = vgg16tf_18.evaluate(test_generator)\n",
    "preds = vgg16tf_18.predict(test_generator)\n",
    "print(added_metrics(preds, test_y_new))\n",
    "\n",
    "vggtf_18_trainloss = epoch_history.history[\"loss\"].copy()\n",
    "vggtf_18_trainauc = epoch_history.history[\"auc\"].copy()\n",
    "vggtf_18_valloss = epoch_history.history[\"val_loss\"].copy()\n",
    "vggtf_18_valauc = epoch_history.history[\"val_auc\"].copy()\n",
    "n = len(epoch_history.history[\"loss\"])\n",
    "\n",
    "# Unfrozen layers 18 onwards for finetuning\n",
    "for id, layer in enumerate(vgg16tf_18.layers):\n",
    "    layer.trainable = False\n",
    "    if id > layer_num:\n",
    "        layer.trainable = True\n",
    "\n",
    "optimizer.learning_rate.assign(1e-5)\n",
    "\n",
    "epoch_history_ft = vgg16tf_18.fit(\n",
    "        train_generator,\n",
    "        epochs=epochs_finetune,\n",
    "        validation_data=test_generator,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=1)\n",
    "\n",
    "vggtf_18_trainloss.extend(epoch_history_ft.history[\"loss\"].copy())\n",
    "vggtf_18_trainauc.extend(epoch_history_ft.history[\"auc\"].copy())\n",
    "vggtf_18_valloss.extend(epoch_history_ft.history[\"val_loss\"].copy())\n",
    "vggtf_18_valauc.extend(epoch_history_ft.history[\"val_auc\"].copy())\n",
    "\n",
    "# Finetuned results\n",
    "loss, accuracy, auc = vgg16tf_18.evaluate(test_generator)\n",
    "preds = vgg16tf_18.predict(test_generator)\n",
    "\n",
    "print(added_metrics(preds, test_y_new))\n",
    "\n",
    "# History.history plots\n",
    "fig, ax = plt.subplots(1,2,figsize=(13,6))\n",
    "\n",
    "ax[0].plot(vggtf_18_trainauc, label=\"train_auc\", color=\"midnightblue\")\n",
    "ax[0].plot(vggtf_18_valauc, label=\"test_auc\", color=\"salmon\")\n",
    "ax[0].axvline(x=n, ymin=0, ymax=10, color=\"midnightblue\", alpha=0.5, linestyle=\"--\")\n",
    "ax[0].set_xlabel(\"Epoch\")\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(vggtf_18_trainloss, label=\"train_loss\", color=\"midnightblue\")\n",
    "ax[1].plot(vggtf_18_valloss, label=\"test_loss\", color=\"salmon\")\n",
    "ax[1].axvline(x=n, ymin=0, ymax=10, color=\"midnightblue\", alpha=0.5, linestyle=\"--\")\n",
    "ax[1].set_xlabel(\"Epoch\")\n",
    "ax[1].legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gradcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_heatmap(vgg16tf_18, X_aug, y_aug_new, \"block5_conv3\", dim=(7,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_heatmap(vgg16tf_18, test_X, test_y_new, \"block5_conv3\", dim=(4,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id = \"xgboost\"></a><span style = \"font-family: Cambria\">**VGG16-XgBoost model**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Splitting\n",
    "benign_train_image, benign_test_image, benign_train_image_label, benign_test_image_label = train_test_split(b_imgs, b_label, test_size = 0.2)\n",
    "malignant_train_image, malignant_test_image, malignant_train_image_label, malignant_test_image_label = train_test_split(m_imgs, m_label, test_size = 0.1)\n",
    "\n",
    "train_image = np.append(benign_train_image, malignant_train_image, axis = 0)\n",
    "test_image = np.append(benign_test_image, malignant_test_image, axis = 0)\n",
    "train_label = np.append(benign_train_image_label, malignant_train_image_label, axis = 0)\n",
    "test_label = np.append(benign_test_image_label, malignant_test_image_label, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(train_image))\n",
    "print(np.shape(test_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "augmented_benign_train_image = augment_images_xgboost(benign_train_image, 600, seed = random.randint(1, 2024))\n",
    "augmented_malignant_train_image = augment_images_xgboost(malignant_train_image, 600, seed = random.randint(1, 2024))\n",
    "\n",
    "train_image = np.append(augmented_benign_train_image, augmented_malignant_train_image, axis = 0)\n",
    "\n",
    "benign_labels = np.zeros((len(augmented_benign_train_image),))\n",
    "malignant_labels = np.ones((len(augmented_malignant_train_image),))\n",
    "\n",
    "train_label = np.append(benign_labels, malignant_labels, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(augmented_benign_train_image))\n",
    "print(np.shape(augmented_malignant_train_image))\n",
    "print(np.shape(train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(train_image))\n",
    "print(np.shape(test_image))\n",
    "print(np.shape(train_label))\n",
    "print(np.shape(test_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style = \"font-family: Cambria\">CNN for Feature Extraction by CNN </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor_model = VGG16(weights = 'imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "for layer in feature_extractor_model.layers:\n",
    "\tlayer.trainable = False\n",
    "\n",
    "train_features = feature_extractor_model.predict(train_image)\n",
    "reshaped_train_features = train_features.reshape(train_features.shape[0], -1)\n",
    "\n",
    "test_features = feature_extractor_model.predict(test_image)\n",
    "reshaped_test_features = test_features.reshape(test_features.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(reshaped_train_features))\n",
    "print(np.shape(reshaped_test_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style = \"font-family: Cambria\">PCA Model </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We explored PCA to reduce the dimensions of flatten features from CNN while still retaining variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_model = PCA(n_components = 1000)\n",
    "feature_pca = pca_model.fit_transform(reshaped_train_features)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "scatter = ax.scatter(feature_pca[:, 0], feature_pca[:, 1], feature_pca[:, 2], c = train_label, cmap='viridis')\n",
    "plt.colorbar(scatter, label='Digit', ticks=range(10))\n",
    "ax.set_xlabel('Principal Component 1')\n",
    "ax.set_ylabel('Principal Component 2')\n",
    "ax.set_zlabel('Principal Component 3')\n",
    "ax.view_init(30, 75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(1, len(pca_model.explained_variance_ratio_) + 1), pca_model.explained_variance_ratio_, alpha=0.5, align='center')\n",
    "plt.step(range(1, len(pca_model.explained_variance_ratio_) + 1), np.cumsum(pca_model.explained_variance_ratio_), where='mid')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal components')\n",
    "plt.title('Explained Variance vs. Number of Principal Components')\n",
    "plt.axhline(y=0.8, color='r', linestyle='--', label='Threshold (0.8)') # Shown at approx. 250\n",
    "plt.axhline(y=0.9, color='b', linestyle='--', label='Threshold (0.9)') # Shown at approx. 450\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel='linear')\n",
    "clf = model.fit(reshaped_train_features, train_label)\n",
    "\n",
    "z = lambda x,y: (clf.coef_[0][0]*x +clf.coef_[0][1]*y) / (clf.coef_[0][2]+0.1)\n",
    "\n",
    "# Plot the decision plane in 3D\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "scatter = ax.scatter(feature_pca[:, 0], feature_pca[:, 2], feature_pca[:, 1], c = train_label, cmap='viridis')\n",
    "plt.colorbar(scatter, label='Digit', ticks=range(10))\n",
    "ax.set_xlabel('Principal Component 2')\n",
    "ax.set_ylabel('Principal Component 3')\n",
    "ax.set_zlabel('Principal Component 1')\n",
    "\n",
    "tmp = np.linspace(-400, 400,10)\n",
    "x,y = np.meshgrid(tmp,tmp)\n",
    "# Plot the decision plane surface\n",
    "ax.plot_surface(x, y, z(x,y))\n",
    "ax.view_init(20, 45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows how PCA could make a significant distinction across the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final PCA Model\n",
    "\n",
    "pca_model = PCA(n_components = 450)\n",
    "reduced_features_450 = pca_model.fit_transform(reshaped_train_features)\n",
    "reduced_features_250 = reduced_features_450[:, :250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(reduced_features_450))\n",
    "print(np.shape(reduced_features_250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features_450 = pca_model.transform(reshaped_test_features)\n",
    "test_features_250 = test_features_450[:,:250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(test_features_450))\n",
    "print(np.shape(test_features_250))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style = \"font-family: Cambria\">XGBoost using the extracted features</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_transform(features, labels):\n",
    "  matrix = XGBoost.DMatrix(features, label = labels)\n",
    "  return matrix\n",
    "\n",
    "\n",
    "def model_fitting(model, features, labels):\n",
    "\n",
    "    xgb_param = model.get_xgb_params()\n",
    "    xgtrain = data_transform(features, labels = labels)\n",
    "    cvresult = XGBoost.cv(xgb_param, xgtrain, num_boost_round=model.get_params()['n_estimators'], nfold = 5,\n",
    "            metrics='auc', early_stopping_rounds = 20)\n",
    "    model.set_params(n_estimators = cvresult.shape[0])\n",
    "\n",
    "    #Fit the algorithm on the data\n",
    "    model.fit(features, labels, eval_metric='auc')\n",
    "\n",
    "    #Predict training set:\n",
    "    dtrain_predictions = model.predict(features)\n",
    "    dtrain_predprob = model.predict_proba(features)[:,1]\n",
    "\n",
    "    #Print model report:\n",
    "    print (\"\\nModel Report\")\n",
    "    print (\"Accuracy : \")\n",
    "    print(sklearn.metrics.accuracy_score(labels, dtrain_predictions))\n",
    "    print(\" \")\n",
    "    print (\"AUC Score (Train): \")\n",
    "    print(sklearn.metrics.roc_auc_score(labels, dtrain_predprob))\n",
    "\n",
    "    feat_imp = pd.Series(model.booster().get_fscore()).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind = 'bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"font-family: Cambria\">Initializing XGBoost</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_XGBoost = XGBoost.XGBClassifier(learning_rate = 0.1,\n",
    "                                n_estimators = 1000,\n",
    "                                max_depth = 5,\n",
    "                                min_child_weight = 1,\n",
    "                                gamma = 0,\n",
    "                                subsample = 0.8,\n",
    "                                colsample_bytree = 0.8,\n",
    "                                objective = 'binary:logistic',\n",
    "                                nthread = 4,\n",
    "                                scale_pos_weight = 1,\n",
    "                                seed = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"font-family: Cambria\">1. Searching for the best n_estimators</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_param = initial_XGBoost.get_xgb_params()\n",
    "xgtrain = data_transform(reshaped_train_features, labels = train_label)\n",
    "cvresult = XGBoost.cv(xgb_param, xgtrain, num_boost_round = initial_XGBoost.get_params()['n_estimators'], nfold = 5,\n",
    "            metrics='auc', early_stopping_rounds = 20)\n",
    "initial_XGBoost.set_params(n_estimators = cvresult.shape[0])\n",
    "\n",
    "#Fit the algorithm on the data\n",
    "initial_XGBoost.fit(reshaped_train_features, train_label, eval_metric='auc')\n",
    "\n",
    "print(cvresult.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of the best number of trees (n_estimators) is 449"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"font-family: Cambria\">2. Tuning max_depth and min_child_weight </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_XGBoost = XGBoost.XGBClassifier(learning_rate = 0.1, \n",
    "                                                  n_estimators = 449, \n",
    "                                                  max_depth=5,\n",
    "                                                  min_child_weight=1, \n",
    "                                                  gamma=0, \n",
    "                                                  subsample=0.8, \n",
    "                                                  colsample_bytree=0.8,\n",
    "                                                  objective= 'binary:logistic', \n",
    "                                                  nthread=4, \n",
    "                                                  scale_pos_weight=1,\n",
    "                                                  seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_2 = {\n",
    " 'max_depth':range(3,10,1),\n",
    " 'min_child_weight':range(1,6,1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_2 = GridSearchCV(second_XGBoost, param_grid = param_grid_2, scoring = 'roc_auc', n_jobs = 1 , cv = 5, verbose = 2)\n",
    "\n",
    "grid_search_2.fit(reshaped_train_features,train_label)\n",
    "print(grid_search_2.best_estimator_)\n",
    "print(grid_search_2.best_params_)\n",
    "print(grid_search_2.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best parameters for both max_depth and min_child_weight is 3 and 1 respectively.\n",
    "\n",
    "The best auc score for this classifier is 0.9921755829903978"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"font-family: Cambria\">3. Tuning Gamma</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_XGBoost = XGBoost.XGBClassifier(learning_rate = 0.1, \n",
    "                                                  n_estimators = 449, \n",
    "                                                  max_depth=3,\n",
    "                                                  min_child_weight=1, \n",
    "                                                  gamma=0, \n",
    "                                                  subsample=0.8, \n",
    "                                                  colsample_bytree=0.8,\n",
    "                                                  objective= 'binary:logistic', \n",
    "                                                  nthread=4, \n",
    "                                                  scale_pos_weight=1,\n",
    "                                                  seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_3 = {\n",
    " 'gamma':[i/10.0 for i in range(0,11)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_3 = GridSearchCV(third_XGBoost, param_grid = param_grid_3, scoring = 'roc_auc', n_jobs = 1 , cv = 5, verbose = 2)\n",
    "\n",
    "grid_search_3.fit(reshaped_train_features,train_label)\n",
    "print(grid_search_3.best_estimator_)\n",
    "print(grid_search_3.best_params_)\n",
    "print(grid_search_3.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best gamma is obtained when gamma = 0.1 with a total auc score of 0.9931851851851852"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"font-family: Cambria\">4. Tuning subsample and colsample_by_tree</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourth_XGBoost = XGBoost.XGBClassifier(learning_rate = 0.1, \n",
    "                                                  n_estimators = 449, \n",
    "                                                  max_depth=3,\n",
    "                                                  min_child_weight=1, \n",
    "                                                  gamma=0.1, \n",
    "                                                  subsample=0.8, \n",
    "                                                  colsample_bytree=0.8,\n",
    "                                                  objective= 'binary:logistic', \n",
    "                                                  nthread=4, \n",
    "                                                  scale_pos_weight=1,\n",
    "                                                  seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_4 = {\n",
    " 'subsample':[i/10.0 for i in range(5,11)],\n",
    " 'colsample_bytree':[i/10.0 for i in range(5,11)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_4 = GridSearchCV(fourth_XGBoost, param_grid = param_grid_4, scoring = 'roc_auc', n_jobs = 5, cv = 5, verbose = 2)\n",
    "\n",
    "grid_search_4.fit(reshaped_train_features,train_label)\n",
    "print(grid_search_4.best_estimator_)\n",
    "print(grid_search_4.best_params_)\n",
    "print(grid_search_4.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best colsample_bytree and subsample is 0.6 and 0.6 respectively, with a final auc score of 0.9932181069958848"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"font-family: Cambria\">5. Tuning the regularization method</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fifth_XGBoost = XGBoost.XGBClassifier(learning_rate = 0.1, \n",
    "                                                  n_estimators = 449, \n",
    "                                                  max_depth=3,\n",
    "                                                  min_child_weight=1, \n",
    "                                                  gamma=0.1, \n",
    "                                                  subsample=0.6,\n",
    "                                                  colsample_bytree=0.6,\n",
    "                                                  objective= 'binary:logistic', \n",
    "                                                  nthread=4, \n",
    "                                                  scale_pos_weight=1,\n",
    "                                                  seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_5 = {\n",
    " 'reg_alpha':[1e-5, 1e-4, 1e-3, 1e-2, 0.1, 1, 10, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_5 = GridSearchCV(fifth_XGBoost, param_grid = param_grid_5, scoring = 'roc_auc', n_jobs = 1 , cv = 5, verbose = 2)\n",
    "\n",
    "grid_search_5.fit(reshaped_train_features,train_label)\n",
    "print(grid_search_5.best_estimator_)\n",
    "print(grid_search_5.best_params_)\n",
    "print(grid_search_5.best_score_)\n",
    "\n",
    "print(grid_searh_5.best_params_[\"reg_alpha\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best reg_alpha is 0.1 with the final auc_score 0.9934156378600824"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"font-family: Cambria\">6. Minimizing learning rate, and adjusting number of boosting rounds for better results</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sixth_XGBoost = XGBoost.XGBClassifier(learning_rate = 0.01, \n",
    "                                                  n_estimators = 449, \n",
    "                                                  max_depth=3,\n",
    "                                                  min_child_weight=1, \n",
    "                                                  gamma=0.1, \n",
    "                                                  subsample=0.6, # change this\n",
    "                                                  colsample_bytree=0.6, #change this\n",
    "                                                  objective= 'binary:logistic', \n",
    "                                                  nthread=4, \n",
    "                                                  scale_pos_weight=1,\n",
    "                                                  reg_alpha = 0.1,\n",
    "                                                  seed = 42) # then add reg_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_param = sixth_XGBoost.get_xgb_params()\n",
    "xgtrain = data_transform(reshaped_train_features, labels = train_label)\n",
    "cvresult = XGBoost.cv(xgb_param, xgtrain, num_boost_round = sixth_XGBoost.get_params()['n_estimators'], nfold = 5,\n",
    "            metrics='auc', early_stopping_rounds = 20)\n",
    "sixth_XGBoost.set_params(n_estimators = cvresult.shape[0], eval_metric='auc')\n",
    "\n",
    "#Fit the algorithm on the data\n",
    "sixth_XGBoost.fit(reshaped_train_features, train_label)\n",
    "\n",
    "print(cvresult.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, this is the end of the tuning algorithm and from the last algo, the best number of estimators are 449."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style = \"font-family: Cambria\">Performance Testing</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = reshaped_test_features\n",
    "test_labels = test_label\n",
    "\n",
    "prediction = sixth_XGBoost.predict_proba(test_features)[:,1]\n",
    "\n",
    "roc_auc = sklearn.metrics.roc_auc_score(test_labels, prediction)\n",
    "fpr, tpr, _ = sklearn.metrics.roc_curve(test_labels, prediction)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_class = sixth_XGBoost.predict(test_features)\n",
    "tn, fp, fn, tp = sklearn.metrics.confusion_matrix(test_label, prediction_class).ravel()\n",
    "\n",
    "# Calculate Precision, Recall, and Accuracy\n",
    "precision = sklearn.metrics.precision_score(test_label, prediction_class)\n",
    "accuracy = sklearn.metrics.accuracy_score(test_label, prediction_class)\n",
    "recall = sklearn.metrics.recall_score(test_label, prediction_class)\n",
    "f1_score = sklearn.metrics.f1_score(test_label, prediction_class)\n",
    "\n",
    "print(\"F1_score:\" ,f1_score)\n",
    "\n",
    "# Calculate ROC AUC Score\n",
    "auc = sklearn.metrics.roc_auc_score(test_label, prediction_class)\n",
    "\n",
    "\n",
    "print(\"True Negatives:\", tn)\n",
    "print(\"False Positives:\", fp)\n",
    "print(\"False Negatives:\", fn)\n",
    "print(\"True Positives:\", tp)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running this cell would require downloading of GraphViz, you can access the same image from the report\n",
    "#XGBoost.plot_tree(sixth_XGBoost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"font-family: Cambria\">Function to Perform all the hyper tuning above</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_parameter_tuning(features, labels, n_jobs = 1, verbose = 0):\n",
    "    \n",
    "    model = XGBoost.XGBClassifier(learning_rate = 0.1,\n",
    "                                n_estimators = 1000,\n",
    "                                max_depth = 5,\n",
    "                                min_child_weight = 1,\n",
    "                                gamma = 0,\n",
    "                                subsample = 0.8,\n",
    "                                colsample_bytree = 0.8,\n",
    "                                objective = 'binary:logistic',\n",
    "                                nthread = 4,\n",
    "                                scale_pos_weight = 1,\n",
    "                                seed = 42)\n",
    "\n",
    "    # Step 1.\n",
    "    xgb_param = model.get_xgb_params()\n",
    "    xgtrain = data_transform(features, labels = labels)\n",
    "    cvresult = XGBoost.cv(xgb_param, xgtrain, num_boost_round = model.get_params()['n_estimators'], nfold = 5,\n",
    "            metrics='auc', early_stopping_rounds = 20)\n",
    "    \n",
    "    model.set_params(n_estimators = cvresult.shape[0])\n",
    "    \n",
    "    print(\"Step 1 Done\")\n",
    "    print(\"Result: Best n_estimators = \" , str(cvresult.shape[0]))\n",
    "\n",
    "    # Step 2.\n",
    "    param_grid_2 = {'max_depth':range(3,10,1),\n",
    "                    'min_child_weight':range(1,6,1)\n",
    "                   }\n",
    "    grid_search_2 = GridSearchCV(model, param_grid = param_grid_2, scoring = 'roc_auc', n_jobs = n_jobs , cv = 5, verbose = verbose)\n",
    "    grid_search_2.fit(features,labels)\n",
    "\n",
    "    model.set_params(max_depth = grid_search_2.best_params_[\"max_depth\"])\n",
    "    model.set_params(min_child_weight = grid_search_2.best_params_[\"min_child_weight\"])\n",
    "\n",
    "    print(\"Step 2 Done\")\n",
    "    print(\"Result: Best max_depth, min_child_weight = \" , str(grid_search_2.best_params_[\"max_depth\"]) , \",\" , \n",
    "          str(grid_search_2.best_params_[\"min_child_weight\"]))\n",
    "\n",
    "    # Step 3.\n",
    "    param_grid_3 = {'gamma':[i/10.0 for i in range(0,11)]}\n",
    "    \n",
    "    grid_search_3 = GridSearchCV(model, param_grid = param_grid_3, scoring = 'roc_auc', n_jobs = n_jobs , cv = 5, verbose = verbose)\n",
    "    grid_search_3.fit(features,labels)\n",
    "\n",
    "    model.set_params(gamma = grid_search_3.best_params_[\"gamma\"])\n",
    "    \n",
    "    print(\"Step 3 Done\")\n",
    "    print(\"Result: Best gamma = \" , str(grid_search_3.best_params_[\"gamma\"]))\n",
    "\n",
    "    # Step 4.\n",
    "    param_grid_4 = {'subsample':[i/10.0 for i in range(5,11)],\n",
    "                    'colsample_bytree':[i/10.0 for i in range(5,11)]}\n",
    "\n",
    "    grid_search_4 = GridSearchCV(model, param_grid = param_grid_4, scoring = 'roc_auc', n_jobs = n_jobs , cv = 5, verbose = verbose)\n",
    "    grid_search_4.fit(features,labels)\n",
    "\n",
    "    model.set_params(subsample = grid_search_4.best_params_[\"subsample\"])\n",
    "    model.set_params(colsample_bytree = grid_search_4.best_params_[\"colsample_bytree\"])\n",
    "\n",
    "    print(\"Step 4 Done\")\n",
    "    print(\"Result: Best subsample, colsample_by_tree = \" , str(grid_search_4.best_params_[\"subsample\"]) , \",\" , \n",
    "          str(grid_search_4.best_params_[\"colsample_bytree\"]))\n",
    "\n",
    "    # Step 5.\n",
    "    param_grid_5 = {'reg_alpha':[1e-5, 1e-4, 1e-3, 1e-2, 0.1, 1, 10, 100]}\n",
    "\n",
    "    grid_search_5 = GridSearchCV(model, param_grid = param_grid_5, scoring = 'roc_auc', n_jobs = n_jobs , cv = 5, verbose = verbose)\n",
    "    grid_search_5.fit(features,labels)    \n",
    "\n",
    "    model.set_params(reg_alpha = grid_search_5.best_params_[\"reg_alpha\"])\n",
    "\n",
    "    print(\"Step 5 Done\")\n",
    "    print(\"Result: Best reg_alpha = \" , str(grid_search_5.best_params_[\"reg_alpha\"]))\n",
    "\n",
    "    # Step 6.\n",
    "    xgb_param = model.get_xgb_params()\n",
    "    xgtrain = data_transform(features, labels = labels)\n",
    "    cvresult = XGBoost.cv(xgb_param, xgtrain, num_boost_round = model.get_params()['n_estimators'], nfold = 5,\n",
    "            metrics='auc', early_stopping_rounds = 20)\n",
    "    model.set_params(n_estimators = cvresult.shape[0])\n",
    "\n",
    "    model.fit(features, labels)\n",
    "            \n",
    "    print(\"Step 6 Done\")\n",
    "    print(\"Result: Best n_estimators = \" , str(cvresult.shape[0]))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pca_450 = hyper_parameter_tuning(reduced_features_450, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pca_250 = hyper_parameter_tuning(reduced_features_250, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = test_features_450\n",
    "test_labels = test_label\n",
    "\n",
    "prediction = model_pca_450.predict_proba(test_features)[:,1]\n",
    "\n",
    "roc_auc = sklearn.metrics.roc_auc_score(test_labels, prediction)\n",
    "fpr, tpr, _ = sklearn.metrics.roc_curve(test_labels, prediction)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_class = model_pca_450.predict(test_features)\n",
    "tn, fp, fn, tp = sklearn.metrics.confusion_matrix(test_label, prediction_class).ravel()\n",
    "\n",
    "# Calculate Precision, Recall, and Accuracy\n",
    "precision = sklearn.metrics.precision_score(test_label, prediction_class)\n",
    "accuracy = sklearn.metrics.accuracy_score(test_label, prediction_class)\n",
    "recall = sklearn.metrics.recall_score(test_label, prediction_class)\n",
    "\n",
    "# Calculate ROC AUC Score\n",
    "auc = sklearn.metrics.roc_auc_score(test_label, prediction_class)\n",
    "\n",
    "print(\"True Negatives:\", tn)\n",
    "print(\"False Positives:\", fp)\n",
    "print(\"False Negatives:\", fn)\n",
    "print(\"True Positives:\", tp)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = test_features_250\n",
    "test_labels = test_label\n",
    "\n",
    "prediction = model_pca_250.predict_proba(test_features)[:,1]\n",
    "\n",
    "roc_auc = sklearn.metrics.roc_auc_score(test_labels, prediction)\n",
    "fpr, tpr, _ = sklearn.metrics.roc_curve(test_labels, prediction)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_class = model_pca_250.predict(test_features)\n",
    "tn, fp, fn, tp = sklearn.metrics.confusion_matrix(test_label, prediction_class).ravel()\n",
    "\n",
    "# Calculate Precision, Recall, and Accuracy\n",
    "precision = sklearn.metrics.precision_score(test_label, prediction_class)\n",
    "accuracy = sklearn.metrics.accuracy_score(test_label, prediction_class)\n",
    "recall = sklearn.metrics.recall_score(test_label, prediction_class)\n",
    "f1_score = sklearn.metrics.f1_score(test_label, prediction_class)\n",
    "\n",
    "print(\"F1_score:\" ,f1_score)\n",
    "\n",
    "# Calculate ROC AUC Score\n",
    "auc = sklearn.metrics.roc_auc_score(test_label, prediction_class)\n",
    "\n",
    "print(\"True Negatives:\", tn)\n",
    "print(\"False Positives:\", fp)\n",
    "print(\"False Negatives:\", fn)\n",
    "print(\"True Positives:\", tp)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
